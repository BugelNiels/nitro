<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "https://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=9"/>
<meta name="generator" content="Doxygen 1.9.1"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>NITRO: List of papers/code that are using/citing ꟻLIP</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<link href="navtree.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="resize.js"></script>
<script type="text/javascript" src="navtreedata.js"></script>
<script type="text/javascript" src="navtree.js"></script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
<link href="doxygen-awesome.css" rel="stylesheet" type="text/css"/>
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr style="height: 56px;">
  <td id="projectlogo"><img alt="Logo" src="logo48x48.png"/></td>
  <td id="projectalign" style="padding-left: 0.5em;">
   <div id="projectname">NITRO
   &#160;<span id="projectnumber">v1.1.1</span>
   </div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.9.1 -->
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:cf05388f2679ee054f2beb29a391d25f4e673ac3&amp;dn=gpl-2.0.txt GPL-v2 */
var searchBox = new SearchBox("searchBox", "search",false,'Search','.html');
/* @license-end */
</script>
<script type="text/javascript" src="menudata.js"></script>
<script type="text/javascript" src="menu.js"></script>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:cf05388f2679ee054f2beb29a391d25f4e673ac3&amp;dn=gpl-2.0.txt GPL-v2 */
$(function() {
  initMenu('',true,false,'search.php','Search');
  $(document).ready(function() { init_search(); });
});
/* @license-end */</script>
<div id="main-nav"></div>
</div><!-- top -->
<div id="side-nav" class="ui-resizable side-nav-resizable">
  <div id="nav-tree">
    <div id="nav-tree-contents">
      <div id="nav-sync" class="sync"></div>
    </div>
  </div>
  <div id="splitbar" style="-moz-user-select:none;" 
       class="ui-resizable-handle">
  </div>
</div>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:cf05388f2679ee054f2beb29a391d25f4e673ac3&amp;dn=gpl-2.0.txt GPL-v2 */
$(document).ready(function(){initNavTree('md_external_flip_misc_papersUsingFLIP.html',''); initResizable(); });
/* @license-end */
</script>
<div id="doc-content">
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<iframe src="javascript:void(0)" frameborder="0" 
        name="MSearchResults" id="MSearchResults">
</iframe>
</div>

<div class="PageDoc"><div class="header">
  <div class="headertitle">
<div class="title">List of papers/code that are using/citing ꟻLIP </div>  </div>
</div><!--header-->
<div class="contents">
<div class="textblock"><p>Please let us know if you know of more papers that use/cite ꟻLIP.</p>
<p><b>Using ꟻLIP:</b></p><ol type="1">
<li>Jae-Ho Nah, <a href="https://dl.acm.org/doi/abs/10.1145/3414685.3417787">"QuickETC2: Fast ETC2 texture compression using Luma differences"</a>, <em>ACM Transactions on Graphics (SIGGRAPH Asia)</em>, November 2020 Article No. 270</li>
</ol>
<ol type="1">
<li>Johanna Engman and Hanna Nilsson, <a href="https://lup.lub.lu.se/luur/download?func=downloadFile&amp;recordOId=9022150&amp;fileOId=9022160">"A Novel Perceptual Metric in Machine Learning"</a>, Master's thesis, Lund University, 2020.</li>
</ol>
<ol type="1">
<li>Finn, Sinclair, <a href="ideals.illinois.edu/handle/2142/109178">"Spatio-temporal reprojection for virtual and augmented reality applications"</a>, <em>Bachelor thesis</em>, 2020.</li>
</ol>
<ol type="1">
<li>Márcio C. F. Macedo and Antônio L. Apolinário Jr., <a href="https://link.springer.com/article/10.1007/s11554-020-01055-x">"Live user-guided depth map estimation for single images"</a>, <em>Journal of Real-Time Image Processing</em>, 2021.</li>
</ol>
<ol type="1">
<li>T. Neff, P. Stadlbauer, M. Parger, A. Kurz, C. R. A. Chaitanya, A. Kaplanyan, M. Steinberger, <a href="https://depthoraclenerf.github.io/">"DONeRF: Towards Real-Time Rendering of Neural Radiance Fields using Depth Oracle Networks"</a>, <em>arXiv</em>:2103.03231, 2021.</li>
</ol>
<ol type="1">
<li>Muhammad Huzaifa, Rishi Desai, Samuel Grayson, Xutao Jiang, Ying Jing, Jae Lee, Fang Lu, Yihan Pang, Joseph Ravichandran, Finn Sinclair, Boyuan Tian, Hengzhi Yuan, Jeffrey Zhang, Sarita V. Adve, <a href="https://arxiv.org/abs/2004.04643">"Exploring Extended Reality with ILLIXR: A New Playground for Architecture Research"</a>, <em>arXiv</em>:2004.04643, 2021.</li>
</ol>
<ol type="1">
<li>Jon Hasselgren, Jacob Munkberg, Jaakko Lehtinen, Miika Aittala, and Samuli Laine, <a href="https://arxiv.org/abs/2104.03989">"Appearance-Driven Automatic 3D Model Simplification"</a>, <em>arXiv</em>:2104.03989, 2021.</li>
</ol>
<ol type="1">
<li>Jozef Hladky, Hans-Peter Seidel, and Markus Steinberger, <a href="https://www.markussteinberger.net/papers/SnakeBinning.pdf">"SnakeBinning: Efficient Temporally Coherent Triangle Packing for Shading Streaming"</a>, <em>Eurographics</em>, 2021.</li>
</ol>
<ol type="1">
<li>Joerg H. Mueller, Thomas Neff, Philip Voglreiter, Markus Steinberger, and Dieter Schmalstieg, <a href="https://dl.acm.org/doi/10.1145/3446790">"Temporally Adaptive Shading Reuse for Real-Time Rendering and Virtual Reality"</a>, <em>ACM Transactions on Graphics</em>, April 2021, Article No.: 11, 2021. <em>Note: they use FLIP in their video, but not in the paper.</em></li>
</ol>
<ol type="1">
<li>Chris Wyman and Alexey Panteleev, <a href="https://research.nvidia.com/publication/2021-07_Rearchitecting-Spatiotemporal-Resampling">"Rearchitecting Spatiotemporal Resampling for Production"</a>, <em>High Performance Graphics</em>, 2021.</li>
</ol>
<ol type="1">
<li>Jonathan Granskog, Till Schnabel, Fabrice Rousselle, and Jan Novak, <a href="https://research.nvidia.com/publication/2021-06_Neural-Scene-Graph">"Neural Scene Graph Rendering"</a>, <em>ACM Transactions on Graphics (SIGGRAPH)</em>, 2021. (used in supplemental)</li>
</ol>
<ol type="1">
<li>Thomas Muller, Fabrice Rousselle, Jan Novak, Alex Keller, <a href="https://research.nvidia.com/publication/2021-06_Real-time-Neural-Radiance">"Real-time Neural Radiance Caching for Path Tracing"</a>, <em>ACM Transactions on Graphics (SIGGRAPH)</em>, 2021.</li>
</ol>
<ol type="1">
<li>Hendrik Baatz, Jonathan Granskog, Marios Papas, Fabrice Rousselle, and Jan Novák, <a href="https://research.nvidia.com/publication/2021-06_NeRF-Tex%3A-Neural-Reflectance">"NeRF-Tex: Neural Radiance Field Textures"</a>, <em>Eurographics Symposium on Rendering</em>, 2021.</li>
</ol>
<ol type="1">
<li>Philippe Weier, Marc Droske, Johannes Hanika, Andrea Weidlich, and Jiří Vorba, <a href="https://weiphil.github.io/portfolio/static/media/OPSR_EGSR2021.8a740716.pdf">"Optimised Path Space Regularisation"</a>, <em>Eurographics Symposium on Rendering</em>, 2021.</li>
</ol>
<ol type="1">
<li>Herman Hansson Söderlund, <a href="http://www.diva-portal.org/smash/get/diva2:1571860/FULLTEXT02.pdf">"Hardware-Accelerated Ray Tracing of Implicit Surfaces"</a>, Master's thesis, BTH, May 2021.</li>
</ol>
<ol type="1">
<li>X. Zhang, M. Manzi, T. Vogels, H. Dahlberg, M. Gross, and M. Papas, <a href="https://cgl.ethz.ch/publications/papers/paperZhan21a.php">"Deep Compositional Denoising for High-quality Monte Carlo Rendering"</a>, <em>Eurographics Symposium on Rendering</em>, 2021.</li>
</ol>
<ol type="1">
<li>Alan Wolfe, <a href="https://link.springer.com/content/pdf/10.1007%2F978-1-4842-7185-8.pdf">"Using Blue Noise for Ray Traced Soft Shadows"</a>, chapter 24, in <em>Ray Tracing Gems 2</em>, edited by Marrs, Shirley, and Wald, 2021.</li>
</ol>
<ol type="1">
<li>Nate Morrical and Stefan Zellman, <a href="https://link.springer.com/content/pdf/10.1007%2F978-1-4842-7185-8.pdf">"Inverse Transform Sampling using Ray Tracing Hardware"</a>, chapter 39, in <em>Ray Tracing Gems 2</em>, edited by Marrs, Shirley, and Wald, 2021.</li>
</ol>
<ol type="1">
<li>Nikolai Hoffman and Alex Evans, <a href="https://link.springer.com/content/pdf/10.1007%2F978-1-4842-7185-8.pdf">"Efficient Unbiased Volume Path Tracing on the GPU"</a>, chapter 43, in <em>Ray Tracing Gems 2</em>, edited by Marrs, Shirley, and Wald, 2021.</li>
</ol>
<ol type="1">
<li>Magdalena Martinek, Philip Thiemann, and Marc Stamminger, <a href="https://www.sciencedirect.com/science/article/abs/pii/S0097849321001394">"Spatio-temporal filtered motion DAGs for path-tracing"</a>, Computers &amp; Graphics, Volume 99, pp. 224-233, October 2021.</li>
</ol>
<ol type="1">
<li>Alexander Dahlinand Veronica Sundstedt, <a href="https://diglib.eg.org/handle/10.2312/cgvc20211319">"Improving Ray Tracing Performance with Variable Rate Shading"</a>, EG UK Computer Graphics and Visual Computing (CGVC), 2021.</li>
</ol>
<ol type="1">
<li>Chao Wang, Bin Chen, Hans-Peter Seidel, Karol Myszkowskil, and Ana Serrano, <a href="https://arxiv.org/pdf/2110.09866.pdf">"Learning a Self-Supervised Tone Mapping Operator via Feature Contrast Masking Loss"</a>, arXiv:2110.09866, 2021.</li>
</ol>
<ol type="1">
<li>Bjoern Haefner, Simon Green, Alan Oursland, Daniel Andersen, Michael Goesele, Daniel Cremers, Richard Newcombe, and Thomas Whelan,<a href="https://research.fb.com/publications/recovering-real-world-reflectance-properties-and-shading-from-hdr-imagery/">"Recovering Real-World Reflectance Properties and Shading From HDR Imagery"</a>, International Conference on 3D Vision, 2021.</li>
</ol>
<ol type="1">
<li>Muhammad Huzaifa, Rishi Desai, Samuel Grayson, Xutao Jiang, Ying Jing, Jae Lee, Fang Lu, Yihan Pang, Joseph Ravichandran, Finn Sinclair, Boyuan Tian, Hengzhi Yuan, Jeffrey Zhang, and Sarita V. Adve, <a href="http://rsim.cs.illinois.edu/Pubs/IISWC_2021_ILLIXR.pdf">"ILLIXR: Enabling End-to-End Extended Reality Research"</a>, IEEE International Symposium on Workload Characterization, 2021.</li>
</ol>
<ol type="1">
<li>Albert Garifullin, Vladimir Frolov, and Anastasiya Khlupina, <a href="http://ceur-ws.org/Vol-3027/paper9.pdf">"Approximate Instancing for Modeling Plant Ecosystems"</a>, GraphiCon 2021.</li>
</ol>
<ol type="1">
<li>Pierre Moreau and Michael Doggett, <a href="https://fileadmin.cs.lth.se/graphics/research/papers/2022/indirectly_visible_caustics/">"Real-Time Rendering of Indirectly Visible Caustics"</a>, GRAPP, 2022.</li>
</ol>
<ol type="1">
<li>Alan Wolfe, Nathan Morrical, Tomas Akenine-Möller, and Ravi Ramamoorthi, <a href="https://arxiv.org/abs/2112.09629">"Scalar Spatiotemporal Blue Noise Masks"</a>, arXiv:2112.09629, 2021.</li>
</ol>
<ol type="1">
<li>Pierre Moreau, <a href="https://fileadmin.cs.lth.se/graphics/research/papers/2022/phd_pm/PhD_thesis_Pierre_Moreau.pdf">"Towards Fully Dynamic Surface Illumination in Real-Time Rendering using Acceleration Data Structures"</a>, PhD thesis, Lund University, 2022.</li>
</ol>
<ol type="1">
<li>Mick van der Spoel, Marijn van Wingerden, and L.L. Sharon Ong, <a href="https://openreview.net/pdf?id=J5F7GFz8jvf">"Comparing loss functions for optimization of generative adversarial networks for MR-contrast image-to-image translation"</a>, Proceedings of Machine Learning, 2022.</li>
</ol>
<ol type="1">
<li>Mikhail Derevyannykh, <a href="https://arxiv.org/pdf/2112.09728.pdf">"Real-Time Path-Guiding Based on Parametric Mixture Models"</a>, arXiv:2112.09728, 2021.</li>
</ol>
<ol type="1">
<li>Taras Khakhulin, Denis Korzhenkov, Pavel Solovev, Gleb Sterkin, Timotei Ardelean, and Victor Lempitsky, <a href="https://samsunglabs.github.io/StereoLayers/">"Stereo Magnification with Multi-Layer Images"</a>, arXiv:2201.05023, 2022.</li>
</ol>
<ol type="1">
<li>Yixin Zhuang, <a href="https://arxiv.org/abs/2201.13013">"Filtering In Implicit Neural Networks"</a>, arXiv:2201.13013, 2022.</li>
</ol>
<ol type="1">
<li>Alejandro Cosin Ayerbe and Gustavo Patow, <a href="https://dugi-doc.udg.edu/bitstream/handle/10256/20698/ClusteredVoxel.pdf?sequence=1">"Clustered voxel real-time global illumination"</a>, <em>Computers &amp; Graphics</em>, Volume 103, pp. 75-89, April 2022.</li>
</ol>
<ol type="1">
<li>Arthur Firmino, Jeppe Revall Frisvad, and Henrik Wann Jensen, <a href="http://www.imm.dtu.dk/~jerf/papers/progdenoising_lowres.pdf">"Progressive Denoising of Monte Carlo Rendered Images"</a>, <em>Eurographics</em>, 2022.</li>
</ol>
<ol type="1">
<li>Huan Wang Jian Ren, Zeng Huang. Kyle Olszewski, Menglei Chai, Yun Fu, and Sergey Tulyakov, <a href="https://arxiv.org/pdf/2203.17261.pdf">"R2L: Distilling Neural Radiance Field to Neural Light Field for Efficient Novel View Synthesis"</a>, arXiv:2203.17261, 2022</li>
</ol>
<ol type="1">
<li>T. Neff, J.H. Mueller, M. Steinberger, and D. Schmalstieg, <a href="https://arbook.icg.tugraz.at/schmalstieg/Schmalstieg_405.pdf">"Meshlets and How to Shade Them: A Study on Texture-Space Shading"</a>, Eurographics, 2022.</li>
</ol>
<ol type="1">
<li>Joao Liborio Cardoso, Bernhard Kerbl, Lei Yang, Yury Uralsky, and Michael Wimmer, <a href="https://jaliborc.github.io/rt-percept/paper.pdf">"Training and Predicting Visual Error for Real-Time Applications"</a>, I3D 2022.</li>
</ol>
<ol type="1">
<li>Zhihua Wang, Keshuo Xu, Yang Yang, Jianlei Dong, Shuhang Gu, Lihao Xu, Yuming Fang, and Kede Ma, <a href="https://arxiv.org/abs/2205.13489">"Measuring Perceptual Color Differences of Smartphone Photography"</a>, arXiv:2205.13489, 2022.</li>
</ol>
<ol type="1">
<li>Jacob Munkberg, Jon Hasselgren, Tianchang Shen, Jun Gao, Wenzheng Chen, Alex Evans, Thomas Muller,and Sanja Fidler, <a href="https://arxiv.org/pdf/2111.12503.pdf">"Extracting Triangular 3D Models, Materials, and Lighting From Images"</a>, arXiv:2111.12503, 2021.</li>
</ol>
<ol type="1">
<li>Wanshui Gan, Hongbin Xu, Yi Huang, Shifeng Chen, and Naoto Yokoya, <a href="https://arxiv.org/pdf/2205.14332.pdf">"V4D: Voxel for 4D Novel View Synthesis"</a>, arXiv:2205.14332, 2022.</li>
</ol>
<ol type="1">
<li>Tianye Li, Mira Slavcheva, Michael Zollhoefer Simon Green, Christoph Lassner, Changil Kim, Tanner Schmidt, Steven Lovegrove, Michael Goesele, Richard Newcombe, and Zhaoyang Lv, <a href="https://openaccess.thecvf.com/content/CVPR2022/papers/Li_Neural_3D_Video_Synthesis_From_Multi-View_Video_CVPR_2022_paper.pdf">"Neural 3D Video Synthesis from Multi-view Video"</a>, CVPR 2022.</li>
</ol>
<ol type="1">
<li>Y. Wu, H. Vo, J. Gong, and Z. Zhu, <a href="https://par.nsf.gov/servlets/purl/10286826">"UnityPIC: Unity Point-Cloud Interactive Core"</a>, Eurographics Symposium on Parallel Graphics and Visualization, 2021.</li>
</ol>
<ol type="1">
<li>Alan Wolfe, Nathan Morrical, Tomas Akenine-Möller, and Ravi Ramamoorthi, <a href="https://research.nvidia.com/publication/2022-07_spatiotemporal-blue-noise-masks">"Spatiotemporal Blue Noise Masks"</a>, Eurographics Sympsium on Rendering, 2022.</li>
</ol>
<ol type="1">
<li>Charlie Mrad, <a href="https://lup.lub.lu.se/luur/download?func=downloadFile&amp;recordOId=9091182&amp;fileOId=9091183">"Image Upscaling for Ray Traced Foveated Rendering"</a>, Master's thesis, Lund University, 2022.</li>
</ol>
<ol type="1">
<li>Grigoris Tsopouridis, Ioannis Fudos, and Andreas-Alexandros Vasilakis, <a href="http://graphics.cs.aueb.gr/graphics/docs/papers/DeepOIT.pdf">"Deep Hybrid Order-Independent Transparency"</a>, The Visual Computer, 2022.</li>
</ol>
<ol type="1">
<li>Aamir Mustafa, Hongjie You, and Rafal K. Mantiuk, <a href="https://www.cl.cam.ac.uk/~am2806/assets/papers/LIM_Histogram_Loss.pdf">"A Comparative Study on the Loss Functions for Image Enhancement Networks"</a>, London Imaging Meeting, 2022.</li>
</ol>
<ol type="1">
<li>Yujie Wang, Praneeth Chakravarthula, Qi Sun, and Baoquan Chen, <a href="https://www.immersivecomputinglab.org/wp-content/uploads/2022/07/Hologram_compression_network_11-compressed.pdf">"Joint Neural Phase Retrieval and Compression for Energy- and Computation-Efficient Holography on the Edge"</a>, ACM Transactions on Graphics (Proceedings of SIGGRAPH), 2022.</li>
</ol>
<ol type="1">
<li>Max Oberberger. Matthäus G. Chajdas, and Rüdiger Westermann, <a href="https://dl.acm.org/doi/10.1145/3543871">"Spatiotemporal Variance-Guided Filtering for Motion Blur"</a>, Proceedings of the ACM on Computer Graphics and Interactive Techniques, Volume 5, Issue 3, July 2022.</li>
</ol>
<ol type="1">
<li>Joao Liborio Cardoso, Bernhard Kerbl, Lei Yang, Yury Uralsky, and Michael Wimmer, <a href="https://dl.acm.org/doi/abs/10.1145/3522625">"Training and Predicting Visual Error for Real-Time Applications"</a>, Proceedings of the ACM on Computer Graphics and Interactive Techniques, Volume 5, Issue 1, May 2022.</li>
</ol>
<ol type="1">
<li>Michal Hvězda, <a href="https://dspace.cvut.cz/bitstream/handle/10467/101357/F3-DP-2022-Hvezda-Michal-diploma_thesis.pdf?sequence=-1">"Dynamic Diffuse Global Illumination"</a>, master thesis, Czech Technical University in Prague, 2022.</li>
</ol>
<ol type="1">
<li>Aamir Mustafa, Param Hanji, Rafal K. Mantiuk, <a href="https://arxiv.org/abs/2209.15165">"Distilling Style from Image Pairs for Global Forward and Inverse Tone Mapping"</a>, arXiv:2209.15165, 2022.</li>
</ol>
<ol type="1">
<li>Subin Kim, Sihyun Yu, Jaeho Lee, and Jinwoo Shin, <a href="https://arxiv.org/pdf/2210.06823.pdf">"Scalable Neural Video Representations with Learnable Positional Features"</a>, arXiv:2210.06823, 2022.</li>
</ol>
<ol type="1">
<li>Bingyi Lu, Jiyuan Liu, and Huilin Xiong, <a href="https://ieeexplore.ieee.org/abstract/document/9897917">"Transformation-Based Adversarial Defense Via Sparse Representation"</a>, <em>IEEE International Conference on Image Processing</em>, 2022.</li>
</ol>
<ol type="1">
<li>Keshuo Xu, Zhihua Wang, Yang Yang, Jianlei Dong, Lihao Xu, Yuming Fang, and Kede Ma, <a href="https://ieeexplore.ieee.org/abstract/document/9897498">"A Database of Visual Color Differences of Modern Smartphone Photography"</a>, <em>IEEE International Conference on Image Processing</em>, 2022.</li>
</ol>
<ol type="1">
<li>George Corrêa de Araújo and Helio Pedrini, <a href="https://arxiv.org/abs/2210.03743">"Single Image Super-Resolution Based on Capsule Neural Networks"</a>, <em>arXiv:2210.03743</em> 2022.</li>
</ol>
<ol type="1">
<li>Ling Li, Chunyi Chen, Jun Peng, and Ripei Zhang, <a href="https://ietresearch.onlinelibrary.wiley.com/doi/pdfdirect/10.1049/ipr2.12681">"Predicting visual difference maps for computer-generated images by integrating human visual system model and deep learning"</a>, IET Image Processing, 2022.</li>
</ol>
<ol type="1">
<li>Feng Wang, Sinan Tan, Xinghang Li, Zeyue Tian, and Huaping Liu, <a href="https://arxiv.org/abs/2212.00190">"Mixed Neural Voxels for Fast Multi-view Video Synthesis"</a>, arXiv:2212.00190, 2022.</li>
</ol>
<ol type="1">
<li>Jozef Hladky, Michael Stengel, Nicholas Vining, Bernhard Kerbl, Hans-Peter Seidel, and Markus Steinberger, <a href="https://dl.acm.org/doi/abs/10.1145/3550454.3555524">"QuadStream: A Quad-Based Scene Streaming Architecture for Novel Viewpoint Reconstruction"</a>, ACM Transactions on Graphics, Volume 41, Issue 6, December 2022.</li>
</ol>
<ol type="1">
<li>Jae-Ho Nah and Hyeju Kim, <a href="https://dl.acm.org/doi/abs/10.1145/3550082.3564204">"TexSR: Image Super-Resolution for High-Quality Texture Mapping"</a>, SIGGRAPH Asia 2022 Posters, December 2022.</li>
</ol>
<ol type="1">
<li>Olivier Therrien, Yannick Levesque, and Guillaume Gilet, <a href="https://link.springer.com/article/10.1007/s00371-022-02703-y">"Screen space indirect lighting with visibility bitmask"</a>, The Visual Computer, 2022.</li>
</ol>
<ol type="1">
<li>Shishira R Maiya, Sharath Girish, Max Ehrlich, Hanyu Wang, Kwot Sin Lee, Patrick Poirson, Pengxiang Wu, Chen Wang, and Abhinav Shrivastava, <a href="https://arxiv.org/pdf/2212.14593.pdf">"NIRVANA: Neural Implicit Representations of Videos with Adaptive Networks and Autoregressive Patch-wise Modeling"</a>, arXiv:2212.1459, 2022.</li>
</ol>
<ol type="1">
<li>Oskar Nyström, <a href="https://www.diva-portal.org/smash/get/diva2:1712288/FULLTEXT02.pdf">"Evaluating PQPM for Usage in Combination with Continuous LOD in VR"</a>, Master's thesis, 2022.</li>
</ol>
<p><b>Citing ꟻLIP (but not using):</b></p><ol type="1">
<li>Jim Nilsson and Tomas Akenine-Möller, <a href="https://arxiv.org/pdf/2006.13846.pdf">"Understanding SSIM"</a>, <em>arXiv:2006.13846v2</em>, 2020.</li>
</ol>
<ol type="1">
<li>Michael N. Mishourovsky, "Visually Lossless Colour Compression Technology", in <em>Smart Algorithms for Multimedia and Imaging</em>, edited by Michael N. Rychagov, Ekaterina V. Tolstaya, and Mikhail Y. Sirotenko, 2021.</li>
</ol>
<ol type="1">
<li>Ha Manh Luu, Theo van Walsum, Daniel Franklin, Phuong Cam Pham, Luu Dang Vu, Adriaan Moelker, Marius Staring, Xiem VanHoang, Wiro Niessen, Nguyen Linh Trung, <a href="https://elastix.lumc.nl/marius/downloads/2021_j_MP.pdf">"Efficiently Compressing 3D Medical Images for Teleinterventions via CNNs and Anisotropic Diffusion"</a>, <em>Medical Physics</em>, 2021.</li>
</ol>
<ol type="1">
<li>Yining Karl Li, <a href="https://blog.yiningkarlli.com/2021/05/porting-takua-to-arm-pt1.html">"Porting Takua Renderer to 64-bit ARM- Part 1"</a>, blog, May 2021.</li>
</ol>
<ol type="1">
<li>Bipul Mohanto, Tariqul Islam, Enrico Gobbetti, and OliverStaadt, <a href="https://www.sciencedirect.com/science/article/pii/S0097849321002211#bb254">"An Integrative View of Foveated Rendering"</a>, Computers &amp; Graphics, October 2021.</li>
</ol>
<ol type="1">
<li>Richard Szeliski, <a href="https://szeliski.org/Book/">Computer Vision: Algorithms and Applications</a>, 2nd ed., 2021.</li>
</ol>
<ol type="1">
<li>Tomas Polasek, David Hrusa, Bedrich Benes, an Martin Čadík, <a href="http://cphoto.fit.vutbr.cz/ictree/">"ICTree: Automatic Perceptual Metrics for Tree Models"</a>, ACM Transactions on Graphics (Proceedings of SIGGRAPH ASIA), 2021.</li>
</ol>
<ol type="1">
<li>Georg Kohl, Li-Wei Chen, and Nils Thuerey, <a href="https://arxiv.org/abs/2202.04109">"Learning Similarity Metrics for Volumetric Simulations with Multiscale CNNs"</a>, arXiv:2202.04109, 2022.</li>
</ol>
<ol type="1">
<li>Cara Tursun and Piotr Didyk, <a href="https://arxiv.org/abs/2205.00108">"Perceptual Visibility Model for Temporal Contrast Changes in Periphery"</a>, arXiv:2205.00108, 2022.</li>
</ol>
<ol type="1">
<li>Rafal K. Mantiuk, Malisha Ashraf, and Alexandre Chapiro, <a href="https://www.cl.cam.ac.uk/~rkm38/pdfs/mantiuk2022_stelaCSF.pdf">"stelaCSF - A Unified Model of Contrast Sensitivity as the Function of Spatio-Temporal Frequency, Eccentricity, Luminance and Area"</a>, SIGGRAPH 2022.</li>
</ol>
<ol type="1">
<li>Jae-Ho Nah, <a href="http://journal.cg-korea.org/archive/view_article?pid=jkcgs-28-2-21">"ASTC Block-Size Determination Method based on PSNR Values"</a>, Journal of the Korea Computer Graphics Society, June 2022.</li>
</ol>
<ol type="1">
<li>Sayantan Datta, Derek Nowrouzezahrai, Christoph Schied, and Zhao Dong, <a href="http://flycooler.com/download/neuralShadowMapping.pdf">"Neural Shadow Mapping"</a>, SIGGRAPH 2022.</li>
</ol>
<ol type="1">
<li>Matilda Tamm, Olivia Shamon, Hector Anadon Leon, Konrad Tollmar, and Linus Gisslén, <a href="https://arxiv.org/abs/2208.12674">"Automatic Testing and Validation of Level of Detail Reductions Through Supervised Learning"</a>, arXiv:2208.12674, 2022.</li>
</ol>
<ol type="1">
<li>David Hrusa, <a href="https://hammer.purdue.edu/articles/thesis/Botanical_Tree_Perceived_Realism_Metric/14579490">"BOTANICAL TREE PERCEIVED REALISM METRIC"</a>, Master's thesis, Purdue University, 2021.</li>
</ol>
<ol type="1">
<li>Farnood Salehi, Marco Manzi, Gerhard Röthlin, Christopher Schroers, Romman Weber, and Marios Papas, <a href="https://studios.disneyresearch.com/2022/11/30/deep-adaptive-sampling-and-reconstruction-using-analytic-distributions/?utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=deep-adaptive-sampling-and-reconstruction-using-analytic-distributions">"Deep Adaptive Sampling and Reconstruction using Analytic Distributions"</a>, SIGGRAPH Asia, 2022.</li>
</ol>
<ol type="1">
<li>Yasuko Sugito, Javier Vazquez-Corral, Trevor Canham, and Marcelo Bertalmío, <a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9833382&amp;tag=1">"Image Quality Evaluation in Professional HDR/WCG Production Questions the Need for HDR Metrics"</a>, <em>IEEE Transactions on Image Processing</em>, vol. 31, pp. 5163-5177, 2022</li>
</ol>
<ol type="1">
<li>Akshay Jindal, <a href="https://aspace.repository.cam.ac.uk/bitstream/handle/1810/345746/aj577-thesis-opt.pdf?sequence=3&amp;isAllowed=y">"Motion quality models for real-time adaptive rendering"</a>, PhD thesis, University of Cambridge, October 2022.</li>
</ol>
<p><b>Code/frameworks/tools that use ꟻLIP:</b></p><ol type="1">
<li><a href="https://github.com/NVIDIAGameWorks/Falcor">Falcor</a>.</li>
</ol>
<ol type="1">
<li><a href="https://github.com/jeremyong/flop/releases/tag/v1.618">The FLOꟼ tool</a>.</li>
</ol>
<ol type="1">
<li><a href="https://github.com/mmp/pbrt-v4/">PBRT v4</a> </li>
</ol>
</div></div><!-- contents -->
</div><!-- PageDoc -->
</div><!-- doc-content -->
<!-- start footer part -->
<div id="nav-path" class="navpath"><!-- id is needed for treeview function! -->
  <ul>
    <li class="footer">Generated by <a href="https://www.doxygen.org/index.html"><img class="footer" src="doxygen.svg" width="104" height="31" alt="doxygen"/></a> 1.9.1 </li>
  </ul>
</div>
</body>
</html>
